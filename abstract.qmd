---
title: "Abstract"
format: html
editor: visual
---

## Scalable Estimation of Semiparametric Latent Variable Models

Latent variable models are ubiquitous in the social sciences, where the traits we want to study are not directly observable, but instead must be probed indirectly through a set of repeated measurements. Examples include surveys that investigate people's political orientation, and measurement of cognitive ability through a set of tests. One of the most comprehensive frameworks for latent variable modeling, and definitely the most comprehensible to statisticians, is generalized linear latent and mixed models (GLLAMM) (Rabe-Hesketh, Skrondal, and Pickles, Psychometrika, 69, 2004). One shortcoming of GLLAMM is that the effects are assumed to be purely parametric. For example, in the application motivating this work, we wanted to understand how decline in various cognitive traits in adulthood is correlated across traits, but the nonlinear way in which cognitive abilities depends on age is best treated through semiparametric estimation using regression splines. Thus, in the first part of this talk, I'll define an extension to GLLAMMs which easily incorporates semiparametric estimation, by representing the regression splines as random effects. Next, the current algorithms for estimating GLLAMMs do not scale well with large datasets, and do not handle crossed random effects, both of which are frequently encountered in practice. To this end, I'll present a quasi-Newton algorithm for marginal maximum likelihood estimation of GLLAMMs which combines the Laplace approximation, sparse matrix methods, and algorithmic differentation. The algorithm estimates GLLAMMs at the same level of accuracy as the currently available algorithms, but orders of magnitude faster. If time permits, I might digress a bit on some implementational issues related to template metaprograming in C++, and show how the analysis of the motivating application turned out.
